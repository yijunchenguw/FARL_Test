variance.cal <- function(theta_matrix, step = 10){
  #  theta_pv1

  W <- 0  # Within-imputation variance
  B <- 0  # Between-imputation variance
  M <- step  # num of Plausible values

  theta_means <- colMeans(theta_matrix) # every dv mean

  grand_mean <- sum(theta_means)/M
  #  Between-Imputation Variance (B)
  B <- sum((theta_means-grand_mean)^2)/(M-1)
  #  Within-Imputation Variance (W)
  for(i in c(1:ncol(theta_matrix))){
    W = W + (sd(theta_matrix[,i])^2)
  }

  # total V
  V <- W/(ncol(theta_matrix)) + (1 + 1/M) * B
  return(V)
}
variance.sample <- function(theta_matrix, step = 10){
  #  theta_pv1

  W <- 0  # Within-imputation variance
  B <- 0  # Between-imputation variance
  M <- step  # num of Plausible values

  theta_means <- colMeans(theta_matrix) # every dv mean

  grand_mean <- sum(theta_means)/M
  #  Between-Imputation Variance (B)
  B <- sum((theta_means-grand_mean)^2)/(M-1)
  #  Within-Imputation Variance (W)
  for(i in c(1:ncol(theta_matrix))){
    W = W + (sd(theta_matrix[,i])^2)
  }

  # total V
  V <- W/ncol(theta_matrix) #+ (1 + 1/M) * B
  return(V)
}
#' Draw Plausible Values from a Fitted Latent Variable Model
#'
#' Generates plausible values (PVs) for latent abilities based on a fitted
#' marginal maximum likelihood (MML) or EM-based latent variable model.
#' The PVs are drawn from subject-specific normal distributions using
#' posterior mean and variance estimates.
#'
#' @param mmlcomp An object returned by a latent variable model fitting
#'   function (e.g., \code{fit_gvem} or a related EM-based estimator), which
#'   contains posterior summaries of latent abilities.
#' @param npv Integer. Number of plausible values to draw for each subject.
#'   Default is \code{10}.
#' @param verbose Logical. If \code{TRUE}, prints progress information during
#'   plausible value generation. Default is \code{TRUE}.
#'
#' @return A data frame containing plausible values, with one row per subject
#'   and \code{npv} columns corresponding to the generated plausible values.
#'
#' @details
#' Plausible values are generated by sampling from the posterior predictive
#' distribution of the latent abilities. For each subject, draws are taken
#' independently from a normal distribution parameterized by the posterior
#' mean and variance obtained from the fitted model. This approach propagates
#' measurement uncertainty in secondary analyses.
#'
#' @export
drawPVs <- function (mmlcomp, npv = 10L,verbose = TRUE) {
  # Define quadrature points (30 points from -4 to 4)
  # Compute EAP estimates for each examinee
  n = nrow(mmlcomp$X)

  resp <- reshape(
    mmlcomp$stuItems,
    idvar = "subject",
    timevar = "key",
    direction = "wide"
  )
  rownames(resp) <- mmlcomp$stuDat[,1]
  resp <- as.matrix(resp[,-1])
  beta_hat <- mmlcomp$coefficients
  studentData <- mmlcomp$stuDat[,-1]
  sigma <- mmlcomp$sigma
  a <- mmlcomp$item_params$slope
  d <- - mmlcomp$item_params$slope*mmlcomp$item_params$difficulty
  c <- mmlcomp$item_params$guessing
  EAP_estimates <- numeric(n)
  EAP_variance <- numeric(n)
  Q <- 30
  t_q <- seq(-4, 4, length.out = Q)  # Quadrature grid

  # Function to compute likelihood for an examinee
  compute_likelihood <- function(response_vector, a, b, t_q) {
    likelihood <- sapply(t_q, function(t) {
      P <- c + (1-c)*(1 / (1 + exp(-a * (t - b))))  # Compute P(X_ij | theta)
      prod((P^response_vector) * ((1 - P)^(1 - response_vector)))  # Compute likelihood
    })
    return(likelihood)
  }
  #theta_pre <- (F %*% (beta) + (E) %*% veta) /norm_c
  output <- if (verbose) stderr() else nullfile()
  cat(file = output, '\n Generating plausible values under FARL framework...\n')
  if (verbose) pb <- txtProgressBar(file = output, 0, length(c(1:n)), style = 3)
  for (i in 1:n) {
    ################
    if (verbose) setTxtProgressBar(pb, pb$getVal() + 1)
    prior_f2 <- dnorm(t_q, mean = studentData[i,]%*%beta_hat, sd = sigma)
    likelihood2 <- compute_likelihood(resp[i, ], a, -(d/a), t_q)  # Compute likelihood at each t_q
    # Compute EAP as weighted mean of t_q
    EAP_estimates[i]  <- sum(t_q * likelihood2 * prior_f2)/sum( likelihood2*prior_f2 )
    EAP_variance[i]  <- sum((t_q-EAP_estimates[i])^2 * likelihood2*prior_f2 )/sum( likelihood2 *prior_f2)
    ################
  }
  eap_mean2 <- mean(EAP_estimates)
  theta_pv <- vector(mode = "numeric",length = n*npv)
  data <- c()
  for (i in seq_len(n)) {
    farl_vals <- numeric(npv)
    for (j in seq_len(npv)) {
      farl_vals[j] <- rnorm(
        1,
        mean = EAP_estimates[i],
        sd   = sqrt(EAP_variance[i])
      )
    }
    data <- rbind(
      data,
      c(subject = i, farl_vals)
    )
  }
  colnames(data) <- c("id", paste0("_farl", seq_len(npv)))
  datPVs <- as.data.frame(data)
  return(datPVs)
  # n <- length(main)
  # # First create all possible combinations of 5 binary variables (2^5 = 32 groups)
  # combinations <- expand.grid(replicate(n, 0:1, simplify = FALSE))
  # colnames(combinations) <- main[1:n]  # Assuming 'main' contains names of your 5 binary variables
  #
  # # Create a list to store results for all subgroups
  # subgroup_results <- list()
  # # Loop through all possible combinations
  # for (i in 1:nrow(combinations)) {
  #
  #   condition_str <- paste(
  #     sapply(1:n, function(j) {
  #       paste0("X_discrete[,", j, "] == ", combinations[i, j])
  #     }),
  #     collapse = " & "
  #   )
  #   # Evaluate the string expression to get a logical vector
  #   condition <- eval(parse(text = condition_str))
  #
  #   # Get IDs for this subgroup
  #   subgroup_ids <- mmlcomp$stuDat[condition,1]
  #
  #   # Store results (excluding ID column)
  #   subgroup_results[[i]] <- datPVs[as.numeric(datPVs$subject) %in% subgroup_ids, -1]
  #
  #   # Optional: name each subgroup (e.g., "00000", "00001", etc.)
  #   names(subgroup_results)[i] <- paste0("result_", paste(combinations[i, ], collapse = ""))
  # }
  #
  # # Now you can access results for any subgroup, e.g.:
  # # result_10101 <- subgroup_results[["result_10101"]]
  # result <-  (datPVs[,-1]) #%>% select(paste0("_dire", c(1:10)))
  #
  # mean_vector <- c()
  # mean_v_vector <- c()
  # var_vector <- c()
  # for (result in subgroup_results) {
  #   mean_vector <- c(mean_vector, mean(colMeans(result)))
  #   var_vector <- c(var_vector, variance.sample(result, step = 10))
  #   mean_v_vector <- c(mean_v_vector, variance.cal(result, step = 10))
  # }
  # return(list(mean = mean_vector, var = var_vector, mean_v = mean_v_vector ))
}
